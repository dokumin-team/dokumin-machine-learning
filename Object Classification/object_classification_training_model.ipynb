{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fungsi untuk mengurai XML Pascal VOC\n",
    "def parse_voc_xml(xml_path):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    objects = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        objects.append((name,))\n",
    "    return objects\n",
    "\n",
    "# Fungsi untuk memuat dataset\n",
    "def load_dataset(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'document': 0, 'KTP': 1, 'KK': 2, 'SIM': 3}  # Pemetaan label ke angka\n",
    "    for folder in [\"train\", \"test\", \"valid\"]:\n",
    "        folder_path = os.path.join(dataset_dir, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".xml\"):\n",
    "                xml_path = os.path.join(folder_path, file)\n",
    "                objects = parse_voc_xml(xml_path)\n",
    "                if len(objects) > 0:  # Pastikan file XML memiliki objek\n",
    "                    image_name = file.replace(\".xml\", \"\") + \".jpg\"  # Asumsi file gambar memiliki nama yang sama dengan file XML\n",
    "                    image_path = os.path.join(folder_path, image_name)\n",
    "                    if os.path.exists(image_path):\n",
    "                        img = cv2.imread(image_path)\n",
    "                        if img is not None:\n",
    "                            img = cv2.resize(img, (256, 256))\n",
    "                            images.append(img)\n",
    "                            labels.append(label_map[objects[0][0]])  # Konversi label string ke angka\n",
    "                        else:\n",
    "                            print(f\"[Warning] Gambar tidak dapat dibaca: {image_path}\")\n",
    "                    else:\n",
    "                        print(f\"[Warning] Path gambar tidak ditemukan: {image_path}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Membuat model CNN\n",
    "def create_model():\n",
    "    input_layer = Input(shape=(256, 256, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(4, activation='softmax')(x)  # Sesuaikan jumlah kelas\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Memuat dataset\n",
    "dataset_dir = \"./dataset\"\n",
    "images, labels = load_dataset(dataset_dir)\n",
    "\n",
    "# Konversi labels menjadi one-hot encoding\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=4)  # 4 adalah jumlah kelas\n",
    "\n",
    "# Memastikan bentuk labels adalah 2D (None, num_classes)\n",
    "print(\"Shape of labels after to_categorical:\", labels.shape)\n",
    "\n",
    "# Membagi dataset menjadi train dan test\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Memastikan dimensi dataset sebelum melatih\n",
    "print(\"Shapes before training:\")\n",
    "print(\"X_train shape:\", X_train.shape)  # Harus (batch_size, 128, 128, 3)\n",
    "print(\"y_train shape:\", y_train.shape)  # Harus (batch_size, num_classes)\n",
    "print(\"X_test shape:\", X_test.shape)    # Harus (batch_size, 128, 128, 3)\n",
    "print(\"y_test shape:\", y_test.shape)    # Harus (batch_size, num_classes)\n",
    "\n",
    "# Membuat model\n",
    "model = create_model()\n",
    "\n",
    "# Menyusun model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Menampilkan ringkasan model\n",
    "model.summary()\n",
    "\n",
    "# Melatih model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "# Mengevaluasi model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan model ke file .h5\n",
    "model.save('model.h5')\n",
    "print(\"Model saved to model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi model ke format .tflite\n",
    "def save_tflite_model(model, output_path):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"Model berhasil disimpan sebagai {output_path}\")\n",
    "\n",
    "# Simpan model ke dalam file .tflite\n",
    "save_tflite_model(model, \"model_klasifikasi.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Memvisualisasikan hasil pelatihan\n",
    "def plot_training_history(history):\n",
    "    # Plot akurasi\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Panggil fungsi untuk menampilkan plot\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Fungsi untuk memuat model .tflite\n",
    "def load_tflite_model(tflite_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "# Fungsi untuk melakukan preprocessing pada gambar\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Gambar tidak dapat dibaca dari path: {image_path}\")\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype('float32') / 255.0  # Normalisasi\n",
    "    img = np.expand_dims(img, axis=0)  # Tambahkan batch dimension\n",
    "    return img\n",
    "\n",
    "# Fungsi untuk menjalankan prediksi menggunakan model .tflite\n",
    "def predict_image(tflite_model_path, image_path, label_map):\n",
    "    # Memuat model .tflite\n",
    "    interpreter = load_tflite_model(tflite_model_path)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Preprocessing gambar\n",
    "    input_data = preprocess_image(image_path)\n",
    "\n",
    "    # Set input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Jalankan model\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Ambil hasil prediksi\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predicted_label = np.argmax(output_data)\n",
    "    confidence = np.max(output_data)\n",
    "\n",
    "    # Tampilkan hasil\n",
    "    label_name = [k for k, v in label_map.items() if v == predicted_label][0]\n",
    "    print(f\"Prediksi: {label_name} (Confidence: {confidence:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping (sama dengan yang digunakan saat melatih model)\n",
    "label_map = {'document': 0, 'KTP': 1, 'KK': 2, 'SIM': 3}\n",
    "\n",
    "# Path model .tflite dan gambar\n",
    "tflite_model_path = \"model_klasifikasi.tflite\"\n",
    "image_path = \"99.jpg\"  # Ganti dengan path gambar yang ingin diuji\n",
    "\n",
    "# Jalankan prediksi\n",
    "predict_image(tflite_model_path, image_path, label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
